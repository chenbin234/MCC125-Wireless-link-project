{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCC125 - Wireless Link Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm \n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import model_Transformer_modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file1 = 'feature_symbol_dataset.csv'\n",
    "output_file_feature = 'feature_symbol_dataset_processing.csv'\n",
    "\n",
    "input_file2 = 'target_symbol_dataset.csv'\n",
    "output_file_target = 'target_symbol_dataset_processing.csv'\n",
    "\n",
    "with open(input_file1, 'r', newline='') as infile, open(output_file_feature, 'w', newline='') as outfile:\n",
    "    reader = csv.reader(infile)\n",
    "    writer = csv.writer(outfile)\n",
    "\n",
    "    for row in reader:\n",
    "        new_row = [cell.replace('i', 'j') for cell in row]\n",
    "        writer.writerow(new_row)\n",
    "\n",
    "with open(input_file2, 'r', newline='') as infile, open(output_file_target, 'w', newline='') as outfile:\n",
    "    reader = csv.reader(infile)\n",
    "    writer = csv.writer(outfile)\n",
    "\n",
    "    for row in reader:\n",
    "        new_row = [cell.replace('i', 'j') for cell in row]\n",
    "        writer.writerow(new_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast  # Used to parse complex numbers from string\n",
    "# Define a function to parse complex numbers from string\n",
    "def complex_parser(s):\n",
    "    try:\n",
    "        return ast.literal_eval(s)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target = pd.read_csv(output_file_target, header=None, converters={col: complex_parser for col in range(len(pd.read_csv(output_file_target).columns))})\n",
    "\n",
    "df_feature = pd.read_csv(output_file_feature, header=None, converters={col: complex_parser for col in range(len(pd.read_csv(output_file_feature).columns))})\n",
    "\n",
    "# filter zero values rows in the dataframe\n",
    "df_target = df_target[df_target.loc[:,0] != 0j]\n",
    "df_feature = df_feature[df_feature.loc[:,0] != 0j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.114876-0.574380j</td>\n",
       "      <td>-0.268044+1.110467j</td>\n",
       "      <td>0.804132+0.650964j</td>\n",
       "      <td>1.033883+0.038292j</td>\n",
       "      <td>0.727548-0.191460j</td>\n",
       "      <td>0.421212+1.110467j</td>\n",
       "      <td>-1.110467+0.880716j</td>\n",
       "      <td>1.187051+0.191460j</td>\n",
       "      <td>-0.114876+0.880716j</td>\n",
       "      <td>-0.344628-0.114876j</td>\n",
       "      <td>0.191460+1.033883j</td>\n",
       "      <td>-1.110467+0.880716j</td>\n",
       "      <td>1.033883-0.497796j</td>\n",
       "      <td>-0.650964+0.191460j</td>\n",
       "      <td>0.191460+0.114876j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.268044-0.804132j</td>\n",
       "      <td>-0.650964-0.344628j</td>\n",
       "      <td>-0.268044+0.727548j</td>\n",
       "      <td>1.110467-0.421212j</td>\n",
       "      <td>1.187051+0.497796j</td>\n",
       "      <td>-0.957299-0.574380j</td>\n",
       "      <td>0.574380-0.114876j</td>\n",
       "      <td>-0.880716+1.033883j</td>\n",
       "      <td>-0.650964+1.033883j</td>\n",
       "      <td>0.650964-1.187051j</td>\n",
       "      <td>1.110467+0.957299j</td>\n",
       "      <td>-0.421212+0.421212j</td>\n",
       "      <td>0.344628-0.574380j</td>\n",
       "      <td>-0.114876+1.187051j</td>\n",
       "      <td>0.421212+0.727548j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.880716+0.650964j</td>\n",
       "      <td>0.497796-0.650964j</td>\n",
       "      <td>-0.344628+0.727548j</td>\n",
       "      <td>1.033883-0.344628j</td>\n",
       "      <td>0.880716-1.110467j</td>\n",
       "      <td>-0.038292+0.268044j</td>\n",
       "      <td>0.191460-0.344628j</td>\n",
       "      <td>0.421212+1.033883j</td>\n",
       "      <td>-0.880716+0.804132j</td>\n",
       "      <td>-0.191460-0.268044j</td>\n",
       "      <td>0.957299-0.344628j</td>\n",
       "      <td>0.727548-0.038292j</td>\n",
       "      <td>0.880716-0.804132j</td>\n",
       "      <td>-0.880716+0.421212j</td>\n",
       "      <td>1.187051+0.574380j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.421212-0.804132j</td>\n",
       "      <td>-0.880716+0.880716j</td>\n",
       "      <td>0.344628+0.497796j</td>\n",
       "      <td>0.344628+1.110467j</td>\n",
       "      <td>0.497796+0.727548j</td>\n",
       "      <td>0.038292-0.804132j</td>\n",
       "      <td>1.033883-0.880716j</td>\n",
       "      <td>0.727548+0.574380j</td>\n",
       "      <td>0.650964+1.110467j</td>\n",
       "      <td>-0.114876-0.191460j</td>\n",
       "      <td>-1.033883-0.268044j</td>\n",
       "      <td>-0.421212+1.033883j</td>\n",
       "      <td>1.110467+0.957299j</td>\n",
       "      <td>-0.727548-0.727548j</td>\n",
       "      <td>-0.880716-0.804132j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.268044+0.957299j</td>\n",
       "      <td>0.880716+1.033883j</td>\n",
       "      <td>-0.574380-0.191460j</td>\n",
       "      <td>0.574380-0.344628j</td>\n",
       "      <td>-1.187051+1.187051j</td>\n",
       "      <td>0.957299+0.191460j</td>\n",
       "      <td>-0.497796+0.727548j</td>\n",
       "      <td>-0.191460-0.497796j</td>\n",
       "      <td>0.421212+0.038292j</td>\n",
       "      <td>0.650964+0.804132j</td>\n",
       "      <td>0.344628+0.344628j</td>\n",
       "      <td>1.033883-0.497796j</td>\n",
       "      <td>0.191460+0.191460j</td>\n",
       "      <td>-0.191460+0.421212j</td>\n",
       "      <td>-0.574380-0.114876j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>-0.880716+0.727548j</td>\n",
       "      <td>-0.344628-1.187051j</td>\n",
       "      <td>-0.804132-0.804132j</td>\n",
       "      <td>-0.727548+0.957299j</td>\n",
       "      <td>0.038292+0.957299j</td>\n",
       "      <td>0.957299-0.650964j</td>\n",
       "      <td>1.187051+0.344628j</td>\n",
       "      <td>1.110467-0.344628j</td>\n",
       "      <td>-1.187051-0.114876j</td>\n",
       "      <td>0.191460-0.574380j</td>\n",
       "      <td>-0.497796+0.727548j</td>\n",
       "      <td>0.804132-1.033883j</td>\n",
       "      <td>-0.497796+1.187051j</td>\n",
       "      <td>0.421212+0.191460j</td>\n",
       "      <td>0.957299+1.110467j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>-1.187051-0.727548j</td>\n",
       "      <td>0.344628-1.110467j</td>\n",
       "      <td>-0.114876-0.421212j</td>\n",
       "      <td>1.033883+0.727548j</td>\n",
       "      <td>-0.727548+0.650964j</td>\n",
       "      <td>0.574380-0.114876j</td>\n",
       "      <td>-0.574380+1.033883j</td>\n",
       "      <td>-0.344628+0.574380j</td>\n",
       "      <td>0.880716-0.114876j</td>\n",
       "      <td>1.187051+0.574380j</td>\n",
       "      <td>-0.880716-0.727548j</td>\n",
       "      <td>-0.191460+0.344628j</td>\n",
       "      <td>-1.110467+1.110467j</td>\n",
       "      <td>0.344628+0.650964j</td>\n",
       "      <td>0.957299+0.268044j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>-0.880716+0.727548j</td>\n",
       "      <td>-0.344628-0.727548j</td>\n",
       "      <td>-0.650964-0.880716j</td>\n",
       "      <td>-1.110467+1.033883j</td>\n",
       "      <td>0.497796+0.268044j</td>\n",
       "      <td>-0.268044-0.804132j</td>\n",
       "      <td>-0.497796-0.574380j</td>\n",
       "      <td>-1.033883+1.110467j</td>\n",
       "      <td>-1.187051+0.574380j</td>\n",
       "      <td>0.804132-0.038292j</td>\n",
       "      <td>-0.727548-0.727548j</td>\n",
       "      <td>0.650964+0.957299j</td>\n",
       "      <td>0.421212+0.957299j</td>\n",
       "      <td>-1.033883+0.268044j</td>\n",
       "      <td>-0.497796-0.268044j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>-0.880716-1.187051j</td>\n",
       "      <td>1.110467-1.033883j</td>\n",
       "      <td>0.650964-0.268044j</td>\n",
       "      <td>1.110467+0.957299j</td>\n",
       "      <td>-0.804132-0.727548j</td>\n",
       "      <td>0.421212+0.344628j</td>\n",
       "      <td>-0.727548-0.727548j</td>\n",
       "      <td>0.957299+0.421212j</td>\n",
       "      <td>-0.038292+0.038292j</td>\n",
       "      <td>0.574380-0.038292j</td>\n",
       "      <td>-0.574380-0.344628j</td>\n",
       "      <td>0.268044-0.114876j</td>\n",
       "      <td>-0.727548-0.650964j</td>\n",
       "      <td>0.957299-0.650964j</td>\n",
       "      <td>0.880716+0.574380j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>-0.880716-1.110467j</td>\n",
       "      <td>-0.727548+0.268044j</td>\n",
       "      <td>0.344628-0.574380j</td>\n",
       "      <td>0.957299+0.038292j</td>\n",
       "      <td>-0.268044-0.804132j</td>\n",
       "      <td>-0.114876+0.497796j</td>\n",
       "      <td>-0.268044+0.191460j</td>\n",
       "      <td>-0.957299-1.110467j</td>\n",
       "      <td>0.574380-0.421212j</td>\n",
       "      <td>-0.038292+0.344628j</td>\n",
       "      <td>-0.191460+0.191460j</td>\n",
       "      <td>0.727548-0.804132j</td>\n",
       "      <td>0.880716-0.268044j</td>\n",
       "      <td>0.268044+1.110467j</td>\n",
       "      <td>-0.344628+0.957299j</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0                   1                   2   \\\n",
       "0    0.114876-0.574380j -0.268044+1.110467j  0.804132+0.650964j   \n",
       "1    0.268044-0.804132j -0.650964-0.344628j -0.268044+0.727548j   \n",
       "2   -0.880716+0.650964j  0.497796-0.650964j -0.344628+0.727548j   \n",
       "3    0.421212-0.804132j -0.880716+0.880716j  0.344628+0.497796j   \n",
       "4    0.268044+0.957299j  0.880716+1.033883j -0.574380-0.191460j   \n",
       "..                  ...                 ...                 ...   \n",
       "145 -0.880716+0.727548j -0.344628-1.187051j -0.804132-0.804132j   \n",
       "146 -1.187051-0.727548j  0.344628-1.110467j -0.114876-0.421212j   \n",
       "147 -0.880716+0.727548j -0.344628-0.727548j -0.650964-0.880716j   \n",
       "148 -0.880716-1.187051j  1.110467-1.033883j  0.650964-0.268044j   \n",
       "149 -0.880716-1.110467j -0.727548+0.268044j  0.344628-0.574380j   \n",
       "\n",
       "                     3                   4                   5   \\\n",
       "0    1.033883+0.038292j  0.727548-0.191460j  0.421212+1.110467j   \n",
       "1    1.110467-0.421212j  1.187051+0.497796j -0.957299-0.574380j   \n",
       "2    1.033883-0.344628j  0.880716-1.110467j -0.038292+0.268044j   \n",
       "3    0.344628+1.110467j  0.497796+0.727548j  0.038292-0.804132j   \n",
       "4    0.574380-0.344628j -1.187051+1.187051j  0.957299+0.191460j   \n",
       "..                  ...                 ...                 ...   \n",
       "145 -0.727548+0.957299j  0.038292+0.957299j  0.957299-0.650964j   \n",
       "146  1.033883+0.727548j -0.727548+0.650964j  0.574380-0.114876j   \n",
       "147 -1.110467+1.033883j  0.497796+0.268044j -0.268044-0.804132j   \n",
       "148  1.110467+0.957299j -0.804132-0.727548j  0.421212+0.344628j   \n",
       "149  0.957299+0.038292j -0.268044-0.804132j -0.114876+0.497796j   \n",
       "\n",
       "                     6                   7                   8   \\\n",
       "0   -1.110467+0.880716j  1.187051+0.191460j -0.114876+0.880716j   \n",
       "1    0.574380-0.114876j -0.880716+1.033883j -0.650964+1.033883j   \n",
       "2    0.191460-0.344628j  0.421212+1.033883j -0.880716+0.804132j   \n",
       "3    1.033883-0.880716j  0.727548+0.574380j  0.650964+1.110467j   \n",
       "4   -0.497796+0.727548j -0.191460-0.497796j  0.421212+0.038292j   \n",
       "..                  ...                 ...                 ...   \n",
       "145  1.187051+0.344628j  1.110467-0.344628j -1.187051-0.114876j   \n",
       "146 -0.574380+1.033883j -0.344628+0.574380j  0.880716-0.114876j   \n",
       "147 -0.497796-0.574380j -1.033883+1.110467j -1.187051+0.574380j   \n",
       "148 -0.727548-0.727548j  0.957299+0.421212j -0.038292+0.038292j   \n",
       "149 -0.268044+0.191460j -0.957299-1.110467j  0.574380-0.421212j   \n",
       "\n",
       "                     9                   10                  11  \\\n",
       "0   -0.344628-0.114876j  0.191460+1.033883j -1.110467+0.880716j   \n",
       "1    0.650964-1.187051j  1.110467+0.957299j -0.421212+0.421212j   \n",
       "2   -0.191460-0.268044j  0.957299-0.344628j  0.727548-0.038292j   \n",
       "3   -0.114876-0.191460j -1.033883-0.268044j -0.421212+1.033883j   \n",
       "4    0.650964+0.804132j  0.344628+0.344628j  1.033883-0.497796j   \n",
       "..                  ...                 ...                 ...   \n",
       "145  0.191460-0.574380j -0.497796+0.727548j  0.804132-1.033883j   \n",
       "146  1.187051+0.574380j -0.880716-0.727548j -0.191460+0.344628j   \n",
       "147  0.804132-0.038292j -0.727548-0.727548j  0.650964+0.957299j   \n",
       "148  0.574380-0.038292j -0.574380-0.344628j  0.268044-0.114876j   \n",
       "149 -0.038292+0.344628j -0.191460+0.191460j  0.727548-0.804132j   \n",
       "\n",
       "                     12                  13                  14  \n",
       "0    1.033883-0.497796j -0.650964+0.191460j  0.191460+0.114876j  \n",
       "1    0.344628-0.574380j -0.114876+1.187051j  0.421212+0.727548j  \n",
       "2    0.880716-0.804132j -0.880716+0.421212j  1.187051+0.574380j  \n",
       "3    1.110467+0.957299j -0.727548-0.727548j -0.880716-0.804132j  \n",
       "4    0.191460+0.191460j -0.191460+0.421212j -0.574380-0.114876j  \n",
       "..                  ...                 ...                 ...  \n",
       "145 -0.497796+1.187051j  0.421212+0.191460j  0.957299+1.110467j  \n",
       "146 -1.110467+1.110467j  0.344628+0.650964j  0.957299+0.268044j  \n",
       "147  0.421212+0.957299j -1.033883+0.268044j -0.497796-0.268044j  \n",
       "148 -0.727548-0.650964j  0.957299-0.650964j  0.880716+0.574380j  \n",
       "149  0.880716-0.268044j  0.268044+1.110467j -0.344628+0.957299j  \n",
       "\n",
       "[150 rows x 15 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.603278-0.092069j</td>\n",
       "      <td>0.509914-0.036396j</td>\n",
       "      <td>0.354361+0.003164j</td>\n",
       "      <td>0.146608+0.028546j</td>\n",
       "      <td>-0.097360+0.043150j</td>\n",
       "      <td>-0.357368+0.051472j</td>\n",
       "      <td>-0.611558+0.058731j</td>\n",
       "      <td>-0.839062+0.070304j</td>\n",
       "      <td>-1.022597+0.091143j</td>\n",
       "      <td>-1.150416+0.125263j</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034822+0.260713j</td>\n",
       "      <td>-0.022812+0.266143j</td>\n",
       "      <td>-0.017089+0.250383j</td>\n",
       "      <td>-0.014873+0.219416j</td>\n",
       "      <td>-0.013996+0.179617j</td>\n",
       "      <td>-0.013044+0.136955j</td>\n",
       "      <td>-0.011413+0.096349j</td>\n",
       "      <td>-0.009085+0.061301j</td>\n",
       "      <td>-0.006428+0.033768j</td>\n",
       "      <td>-0.003976+0.014256j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.574348-0.712335j</td>\n",
       "      <td>0.545541-0.713478j</td>\n",
       "      <td>0.461712-0.711128j</td>\n",
       "      <td>0.334159-0.707626j</td>\n",
       "      <td>0.178102-0.704154j</td>\n",
       "      <td>0.010467-0.700196j</td>\n",
       "      <td>-0.152631-0.693281j</td>\n",
       "      <td>-0.298097-0.679136j</td>\n",
       "      <td>-0.417379-0.652310j</td>\n",
       "      <td>-0.507174-0.607082j</td>\n",
       "      <td>...</td>\n",
       "      <td>0.196721+0.855423j</td>\n",
       "      <td>0.199359+0.792985j</td>\n",
       "      <td>0.184515+0.717407j</td>\n",
       "      <td>0.157780+0.628023j</td>\n",
       "      <td>0.125042+0.526805j</td>\n",
       "      <td>0.091643+0.418203j</td>\n",
       "      <td>0.061773+0.308379j</td>\n",
       "      <td>0.038127+0.204153j</td>\n",
       "      <td>0.021770+0.111928j</td>\n",
       "      <td>0.012345+0.036682j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.875279+0.974010j</td>\n",
       "      <td>0.809136+0.886516j</td>\n",
       "      <td>0.684224+0.767567j</td>\n",
       "      <td>0.505408+0.618022j</td>\n",
       "      <td>0.283969+0.442698j</td>\n",
       "      <td>0.036850+0.250368j</td>\n",
       "      <td>-0.214807+0.053078j</td>\n",
       "      <td>-0.447815-0.134948j</td>\n",
       "      <td>-0.639468-0.298860j</td>\n",
       "      <td>-0.770197-0.425031j</td>\n",
       "      <td>...</td>\n",
       "      <td>0.549205-1.418380j</td>\n",
       "      <td>0.518208-1.440372j</td>\n",
       "      <td>0.478376-1.376485j</td>\n",
       "      <td>0.428478-1.241401j</td>\n",
       "      <td>0.369037-1.055448j</td>\n",
       "      <td>0.302406-0.841566j</td>\n",
       "      <td>0.232382-0.622274j</td>\n",
       "      <td>0.163582-0.417072j</td>\n",
       "      <td>0.100667-0.240540j</td>\n",
       "      <td>0.047521-0.101406j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.857477+0.401416j</td>\n",
       "      <td>0.766454+0.364486j</td>\n",
       "      <td>0.616267+0.266248j</td>\n",
       "      <td>0.416402+0.116723j</td>\n",
       "      <td>0.181517-0.068507j</td>\n",
       "      <td>-0.070192-0.270148j</td>\n",
       "      <td>-0.319149-0.467290j</td>\n",
       "      <td>-0.546647-0.639872j</td>\n",
       "      <td>-0.736961-0.770884j</td>\n",
       "      <td>-0.878933-0.848174j</td>\n",
       "      <td>...</td>\n",
       "      <td>0.796642-0.966437j</td>\n",
       "      <td>0.751355-0.912577j</td>\n",
       "      <td>0.689842-0.834409j</td>\n",
       "      <td>0.612176-0.733404j</td>\n",
       "      <td>0.520900-0.614489j</td>\n",
       "      <td>0.420846-0.485276j</td>\n",
       "      <td>0.318394-0.354916j</td>\n",
       "      <td>0.220436-0.232674j</td>\n",
       "      <td>0.133290-0.126532j</td>\n",
       "      <td>0.061744-0.042055j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.572997-0.701675j</td>\n",
       "      <td>-0.665814-0.705072j</td>\n",
       "      <td>-0.749554-0.701304j</td>\n",
       "      <td>-0.828681-0.692237j</td>\n",
       "      <td>-0.905926-0.679646j</td>\n",
       "      <td>-0.981102-0.664744j</td>\n",
       "      <td>-1.050507-0.647941j</td>\n",
       "      <td>-1.107159-0.628800j</td>\n",
       "      <td>-1.141736-0.606234j</td>\n",
       "      <td>-1.144146-0.578875j</td>\n",
       "      <td>...</td>\n",
       "      <td>0.533896-0.101798j</td>\n",
       "      <td>0.519004-0.078724j</td>\n",
       "      <td>0.483237-0.061527j</td>\n",
       "      <td>0.430283-0.048783j</td>\n",
       "      <td>0.365324-0.039002j</td>\n",
       "      <td>0.294340-0.030933j</td>\n",
       "      <td>0.223364-0.023680j</td>\n",
       "      <td>0.157733-0.016795j</td>\n",
       "      <td>0.101479-0.010201j</td>\n",
       "      <td>0.056995-0.004104j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.646598+0.854384j</td>\n",
       "      <td>0.577590+0.815908j</td>\n",
       "      <td>0.452744+0.766608j</td>\n",
       "      <td>0.277978+0.706989j</td>\n",
       "      <td>0.065072+0.639050j</td>\n",
       "      <td>-0.169781+0.566310j</td>\n",
       "      <td>-0.408098+0.493535j</td>\n",
       "      <td>-0.631652+0.426289j</td>\n",
       "      <td>-0.824930+0.370231j</td>\n",
       "      <td>-0.977091+0.330323j</td>\n",
       "      <td>...</td>\n",
       "      <td>1.023905-0.864738j</td>\n",
       "      <td>1.002944-0.836888j</td>\n",
       "      <td>0.941459-0.780316j</td>\n",
       "      <td>0.845032-0.697652j</td>\n",
       "      <td>0.722251-0.594447j</td>\n",
       "      <td>0.583657-0.478448j</td>\n",
       "      <td>0.440521-0.358604j</td>\n",
       "      <td>0.303536-0.243842j</td>\n",
       "      <td>0.181690-0.141924j</td>\n",
       "      <td>0.081396-0.058517j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>-1.104657-0.975513j</td>\n",
       "      <td>-0.984444-1.018058j</td>\n",
       "      <td>-0.825874-1.053621j</td>\n",
       "      <td>-0.634933-1.083944j</td>\n",
       "      <td>-0.421624-1.109882j</td>\n",
       "      <td>-0.199137-1.131134j</td>\n",
       "      <td>0.017518-1.146315j</td>\n",
       "      <td>0.213200-1.153354j</td>\n",
       "      <td>0.374314-1.150091j</td>\n",
       "      <td>0.490377-1.134840j</td>\n",
       "      <td>...</td>\n",
       "      <td>0.969035+0.421856j</td>\n",
       "      <td>0.925914+0.379784j</td>\n",
       "      <td>0.848542+0.334614j</td>\n",
       "      <td>0.741587+0.286999j</td>\n",
       "      <td>0.613148+0.237976j</td>\n",
       "      <td>0.473701+0.188990j</td>\n",
       "      <td>0.334566+0.141800j</td>\n",
       "      <td>0.206348+0.098310j</td>\n",
       "      <td>0.097476+0.060288j</td>\n",
       "      <td>0.013324+0.029141j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.098147-1.150394j</td>\n",
       "      <td>0.120822-1.075045j</td>\n",
       "      <td>0.170590-0.957223j</td>\n",
       "      <td>0.242345-0.802858j</td>\n",
       "      <td>0.328929-0.622248j</td>\n",
       "      <td>0.422341-0.428766j</td>\n",
       "      <td>0.514919-0.236998j</td>\n",
       "      <td>0.600535-0.060718j</td>\n",
       "      <td>0.675377+0.089095j</td>\n",
       "      <td>0.738335+0.205709j</td>\n",
       "      <td>...</td>\n",
       "      <td>0.525901-0.149427j</td>\n",
       "      <td>0.491115-0.109931j</td>\n",
       "      <td>0.449165-0.084624j</td>\n",
       "      <td>0.399447-0.069968j</td>\n",
       "      <td>0.342853-0.062005j</td>\n",
       "      <td>0.281683-0.057105j</td>\n",
       "      <td>0.219259-0.052449j</td>\n",
       "      <td>0.159404-0.046309j</td>\n",
       "      <td>0.105698-0.038056j</td>\n",
       "      <td>0.060886-0.028025j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.469930+1.641743j</td>\n",
       "      <td>0.316117+1.638584j</td>\n",
       "      <td>0.124937+1.592317j</td>\n",
       "      <td>-0.100350+1.509389j</td>\n",
       "      <td>-0.351531+1.398794j</td>\n",
       "      <td>-0.615954+1.270666j</td>\n",
       "      <td>-0.877827+1.134878j</td>\n",
       "      <td>-1.120170+0.999945j</td>\n",
       "      <td>-1.326876+0.872310j</td>\n",
       "      <td>-1.484804+0.756113j</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.690954-0.965989j</td>\n",
       "      <td>-0.623995-0.963485j</td>\n",
       "      <td>-0.555329-0.916302j</td>\n",
       "      <td>-0.482467-0.830053j</td>\n",
       "      <td>-0.404630-0.714130j</td>\n",
       "      <td>-0.323068-0.580352j</td>\n",
       "      <td>-0.240785-0.441346j</td>\n",
       "      <td>-0.161972-0.308895j</td>\n",
       "      <td>-0.091155-0.192523j</td>\n",
       "      <td>-0.032329-0.098591j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.568657-1.278470j</td>\n",
       "      <td>0.525180-1.238339j</td>\n",
       "      <td>0.432172-1.177112j</td>\n",
       "      <td>0.297300-1.099192j</td>\n",
       "      <td>0.133081-1.009992j</td>\n",
       "      <td>-0.044337-0.915097j</td>\n",
       "      <td>-0.217011-0.819558j</td>\n",
       "      <td>-0.367235-0.727342j</td>\n",
       "      <td>-0.479625-0.641100j</td>\n",
       "      <td>-0.542852-0.562114j</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.938758+0.128463j</td>\n",
       "      <td>-0.881101+0.096906j</td>\n",
       "      <td>-0.802599+0.073442j</td>\n",
       "      <td>-0.704542+0.056014j</td>\n",
       "      <td>-0.591052+0.042474j</td>\n",
       "      <td>-0.468615+0.030988j</td>\n",
       "      <td>-0.345180+0.020298j</td>\n",
       "      <td>-0.228979+0.009832j</td>\n",
       "      <td>-0.127322-0.000342j</td>\n",
       "      <td>-0.045583-0.009710j</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0                   1                   2    \\\n",
       "0    0.603278-0.092069j  0.509914-0.036396j  0.354361+0.003164j   \n",
       "1    0.574348-0.712335j  0.545541-0.713478j  0.461712-0.711128j   \n",
       "2    0.875279+0.974010j  0.809136+0.886516j  0.684224+0.767567j   \n",
       "3    0.857477+0.401416j  0.766454+0.364486j  0.616267+0.266248j   \n",
       "4   -0.572997-0.701675j -0.665814-0.705072j -0.749554-0.701304j   \n",
       "..                  ...                 ...                 ...   \n",
       "145  0.646598+0.854384j  0.577590+0.815908j  0.452744+0.766608j   \n",
       "146 -1.104657-0.975513j -0.984444-1.018058j -0.825874-1.053621j   \n",
       "147  0.098147-1.150394j  0.120822-1.075045j  0.170590-0.957223j   \n",
       "148  0.469930+1.641743j  0.316117+1.638584j  0.124937+1.592317j   \n",
       "149  0.568657-1.278470j  0.525180-1.238339j  0.432172-1.177112j   \n",
       "\n",
       "                    3                   4                   5    \\\n",
       "0    0.146608+0.028546j -0.097360+0.043150j -0.357368+0.051472j   \n",
       "1    0.334159-0.707626j  0.178102-0.704154j  0.010467-0.700196j   \n",
       "2    0.505408+0.618022j  0.283969+0.442698j  0.036850+0.250368j   \n",
       "3    0.416402+0.116723j  0.181517-0.068507j -0.070192-0.270148j   \n",
       "4   -0.828681-0.692237j -0.905926-0.679646j -0.981102-0.664744j   \n",
       "..                  ...                 ...                 ...   \n",
       "145  0.277978+0.706989j  0.065072+0.639050j -0.169781+0.566310j   \n",
       "146 -0.634933-1.083944j -0.421624-1.109882j -0.199137-1.131134j   \n",
       "147  0.242345-0.802858j  0.328929-0.622248j  0.422341-0.428766j   \n",
       "148 -0.100350+1.509389j -0.351531+1.398794j -0.615954+1.270666j   \n",
       "149  0.297300-1.099192j  0.133081-1.009992j -0.044337-0.915097j   \n",
       "\n",
       "                    6                   7                   8    \\\n",
       "0   -0.611558+0.058731j -0.839062+0.070304j -1.022597+0.091143j   \n",
       "1   -0.152631-0.693281j -0.298097-0.679136j -0.417379-0.652310j   \n",
       "2   -0.214807+0.053078j -0.447815-0.134948j -0.639468-0.298860j   \n",
       "3   -0.319149-0.467290j -0.546647-0.639872j -0.736961-0.770884j   \n",
       "4   -1.050507-0.647941j -1.107159-0.628800j -1.141736-0.606234j   \n",
       "..                  ...                 ...                 ...   \n",
       "145 -0.408098+0.493535j -0.631652+0.426289j -0.824930+0.370231j   \n",
       "146  0.017518-1.146315j  0.213200-1.153354j  0.374314-1.150091j   \n",
       "147  0.514919-0.236998j  0.600535-0.060718j  0.675377+0.089095j   \n",
       "148 -0.877827+1.134878j -1.120170+0.999945j -1.326876+0.872310j   \n",
       "149 -0.217011-0.819558j -0.367235-0.727342j -0.479625-0.641100j   \n",
       "\n",
       "                    9    ...                 140                 141  \\\n",
       "0   -1.150416+0.125263j  ... -0.034822+0.260713j -0.022812+0.266143j   \n",
       "1   -0.507174-0.607082j  ...  0.196721+0.855423j  0.199359+0.792985j   \n",
       "2   -0.770197-0.425031j  ...  0.549205-1.418380j  0.518208-1.440372j   \n",
       "3   -0.878933-0.848174j  ...  0.796642-0.966437j  0.751355-0.912577j   \n",
       "4   -1.144146-0.578875j  ...  0.533896-0.101798j  0.519004-0.078724j   \n",
       "..                  ...  ...                 ...                 ...   \n",
       "145 -0.977091+0.330323j  ...  1.023905-0.864738j  1.002944-0.836888j   \n",
       "146  0.490377-1.134840j  ...  0.969035+0.421856j  0.925914+0.379784j   \n",
       "147  0.738335+0.205709j  ...  0.525901-0.149427j  0.491115-0.109931j   \n",
       "148 -1.484804+0.756113j  ... -0.690954-0.965989j -0.623995-0.963485j   \n",
       "149 -0.542852-0.562114j  ... -0.938758+0.128463j -0.881101+0.096906j   \n",
       "\n",
       "                    142                 143                 144  \\\n",
       "0   -0.017089+0.250383j -0.014873+0.219416j -0.013996+0.179617j   \n",
       "1    0.184515+0.717407j  0.157780+0.628023j  0.125042+0.526805j   \n",
       "2    0.478376-1.376485j  0.428478-1.241401j  0.369037-1.055448j   \n",
       "3    0.689842-0.834409j  0.612176-0.733404j  0.520900-0.614489j   \n",
       "4    0.483237-0.061527j  0.430283-0.048783j  0.365324-0.039002j   \n",
       "..                  ...                 ...                 ...   \n",
       "145  0.941459-0.780316j  0.845032-0.697652j  0.722251-0.594447j   \n",
       "146  0.848542+0.334614j  0.741587+0.286999j  0.613148+0.237976j   \n",
       "147  0.449165-0.084624j  0.399447-0.069968j  0.342853-0.062005j   \n",
       "148 -0.555329-0.916302j -0.482467-0.830053j -0.404630-0.714130j   \n",
       "149 -0.802599+0.073442j -0.704542+0.056014j -0.591052+0.042474j   \n",
       "\n",
       "                    145                 146                 147  \\\n",
       "0   -0.013044+0.136955j -0.011413+0.096349j -0.009085+0.061301j   \n",
       "1    0.091643+0.418203j  0.061773+0.308379j  0.038127+0.204153j   \n",
       "2    0.302406-0.841566j  0.232382-0.622274j  0.163582-0.417072j   \n",
       "3    0.420846-0.485276j  0.318394-0.354916j  0.220436-0.232674j   \n",
       "4    0.294340-0.030933j  0.223364-0.023680j  0.157733-0.016795j   \n",
       "..                  ...                 ...                 ...   \n",
       "145  0.583657-0.478448j  0.440521-0.358604j  0.303536-0.243842j   \n",
       "146  0.473701+0.188990j  0.334566+0.141800j  0.206348+0.098310j   \n",
       "147  0.281683-0.057105j  0.219259-0.052449j  0.159404-0.046309j   \n",
       "148 -0.323068-0.580352j -0.240785-0.441346j -0.161972-0.308895j   \n",
       "149 -0.468615+0.030988j -0.345180+0.020298j -0.228979+0.009832j   \n",
       "\n",
       "                    148                 149  \n",
       "0   -0.006428+0.033768j -0.003976+0.014256j  \n",
       "1    0.021770+0.111928j  0.012345+0.036682j  \n",
       "2    0.100667-0.240540j  0.047521-0.101406j  \n",
       "3    0.133290-0.126532j  0.061744-0.042055j  \n",
       "4    0.101479-0.010201j  0.056995-0.004104j  \n",
       "..                  ...                 ...  \n",
       "145  0.181690-0.141924j  0.081396-0.058517j  \n",
       "146  0.097476+0.060288j  0.013324+0.029141j  \n",
       "147  0.105698-0.038056j  0.060886-0.028025j  \n",
       "148 -0.091155-0.192523j -0.032329-0.098591j  \n",
       "149 -0.127322-0.000342j -0.045583-0.009710j  \n",
       "\n",
       "[150 rows x 150 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_symbol = df_target.to_numpy()\n",
    "\n",
    "real_target_symbol = np.real(target_symbol)\n",
    "imag_target_symbol = np.imag(target_symbol)\n",
    "\n",
    "y = np.array([real_target_symbol, imag_target_symbol]).transpose(1, 2, 0)\n",
    "\n",
    "\n",
    "feature_symbol = df_feature.to_numpy()\n",
    "real_feature_symbol = np.real(feature_symbol)\n",
    "imag_feature_symbol = np.imag(feature_symbol)\n",
    "\n",
    "X = np.array([real_feature_symbol, imag_feature_symbol]).transpose(1, 2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.11487594, -0.57437969],\n",
       "        [-0.26804385,  1.11046739],\n",
       "        [ 0.80413156,  0.65096364],\n",
       "        ...,\n",
       "        [ 1.03388343, -0.49779573],\n",
       "        [-0.65096364,  0.1914599 ],\n",
       "        [ 0.1914599 ,  0.11487594]],\n",
       "\n",
       "       [[ 0.26804385, -0.80413156],\n",
       "        [-0.65096364, -0.34462781],\n",
       "        [-0.26804385,  0.7275476 ],\n",
       "        ...,\n",
       "        [ 0.34462781, -0.57437969],\n",
       "        [-0.11487594,  1.18705135],\n",
       "        [ 0.42121177,  0.7275476 ]],\n",
       "\n",
       "       [[-0.88071552,  0.65096364],\n",
       "        [ 0.49779573, -0.65096364],\n",
       "        [-0.34462781,  0.7275476 ],\n",
       "        ...,\n",
       "        [ 0.88071552, -0.80413156],\n",
       "        [-0.88071552,  0.42121177],\n",
       "        [ 1.18705135,  0.57437969]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.88071552,  0.7275476 ],\n",
       "        [-0.34462781, -0.7275476 ],\n",
       "        [-0.65096364, -0.88071552],\n",
       "        ...,\n",
       "        [ 0.42121177,  0.95729948],\n",
       "        [-1.03388343,  0.26804385],\n",
       "        [-0.49779573, -0.26804385]],\n",
       "\n",
       "       [[-0.88071552, -1.18705135],\n",
       "        [ 1.11046739, -1.03388343],\n",
       "        [ 0.65096364, -0.26804385],\n",
       "        ...,\n",
       "        [-0.7275476 , -0.65096364],\n",
       "        [ 0.95729948, -0.65096364],\n",
       "        [ 0.88071552,  0.57437969]],\n",
       "\n",
       "       [[-0.88071552, -1.11046739],\n",
       "        [-0.7275476 ,  0.26804385],\n",
       "        [ 0.34462781, -0.57437969],\n",
       "        ...,\n",
       "        [ 0.88071552, -0.26804385],\n",
       "        [ 0.26804385,  1.11046739],\n",
       "        [-0.34462781,  0.95729948]]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 6.03277520e-01, -9.20685975e-02],\n",
       "        [ 5.09914361e-01, -3.63963129e-02],\n",
       "        [ 3.54361090e-01,  3.16440467e-03],\n",
       "        ...,\n",
       "        [-9.08470535e-03,  6.13007800e-02],\n",
       "        [-6.42816120e-03,  3.37681903e-02],\n",
       "        [-3.97554236e-03,  1.42558204e-02]],\n",
       "\n",
       "       [[ 5.74347854e-01, -7.12334767e-01],\n",
       "        [ 5.45541404e-01, -7.13478488e-01],\n",
       "        [ 4.61712294e-01, -7.11127668e-01],\n",
       "        ...,\n",
       "        [ 3.81273672e-02,  2.04153046e-01],\n",
       "        [ 2.17701975e-02,  1.11927685e-01],\n",
       "        [ 1.23449857e-02,  3.66821135e-02]],\n",
       "\n",
       "       [[ 8.75278510e-01,  9.74009919e-01],\n",
       "        [ 8.09135610e-01,  8.86516386e-01],\n",
       "        [ 6.84224342e-01,  7.67566661e-01],\n",
       "        ...,\n",
       "        [ 1.63581902e-01, -4.17071719e-01],\n",
       "        [ 1.00666936e-01, -2.40540019e-01],\n",
       "        [ 4.75212822e-02, -1.01405987e-01]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 9.81466321e-02, -1.15039433e+00],\n",
       "        [ 1.20821923e-01, -1.07504485e+00],\n",
       "        [ 1.70590054e-01, -9.57223402e-01],\n",
       "        ...,\n",
       "        [ 1.59404310e-01, -4.63089270e-02],\n",
       "        [ 1.05697535e-01, -3.80559275e-02],\n",
       "        [ 6.08860190e-02, -2.80252495e-02]],\n",
       "\n",
       "       [[ 4.69930371e-01,  1.64174297e+00],\n",
       "        [ 3.16117363e-01,  1.63858395e+00],\n",
       "        [ 1.24937087e-01,  1.59231659e+00],\n",
       "        ...,\n",
       "        [-1.61971530e-01, -3.08894530e-01],\n",
       "        [-9.11545231e-02, -1.92522828e-01],\n",
       "        [-3.23291360e-02, -9.85912991e-02]],\n",
       "\n",
       "       [[ 5.68656962e-01, -1.27846970e+00],\n",
       "        [ 5.25179991e-01, -1.23833875e+00],\n",
       "        [ 4.32171829e-01, -1.17711176e+00],\n",
       "        ...,\n",
       "        [-2.28978763e-01,  9.83231653e-03],\n",
       "        [-1.27321895e-01, -3.41687981e-04],\n",
       "        [-4.55826106e-02, -9.70955685e-03]]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 150, 2)\n",
      "(150, 15, 2)\n",
      "150\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.26804385, -0.80413156],\n",
       "       [-0.65096364, -0.34462781],\n",
       "       [-0.26804385,  0.7275476 ],\n",
       "       [ 1.11046739, -0.42121177],\n",
       "       [ 1.18705135,  0.49779573],\n",
       "       [-0.95729948, -0.57437969],\n",
       "       [ 0.57437969, -0.11487594],\n",
       "       [-0.88071552,  1.03388343],\n",
       "       [-0.65096364,  1.03388343],\n",
       "       [ 0.65096364, -1.18705135],\n",
       "       [ 1.11046739,  0.95729948],\n",
       "       [-0.42121177,  0.42121177],\n",
       "       [ 0.34462781, -0.57437969],\n",
       "       [-0.11487594,  1.18705135],\n",
       "       [ 0.42121177,  0.7275476 ]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SymbolDataset(Dataset):\n",
    "    \"\"\"Class to create the torch Dataset object\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y):\n",
    "        super(SymbolDataset, self).__init__()\n",
    "\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.X[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"Total number of samples\"\"\"\n",
    "        return len(self.X[:,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lenght of sequence given to encoder\n",
    "gt = 8\n",
    "# length of sequence given to decoder\n",
    "horizon = 12\n",
    "\n",
    "# defining batch size\n",
    "batch_size = 32\n",
    "\n",
    "# creating torch dataset and dataloaders\n",
    "symbol_dataset = SymbolDataset(X,y)\n",
    "train_loader = DataLoader(symbol_dataset, batch_size, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining model save location\n",
    "save_location = \"./Transformer_models\"\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "tf_model = model_Transformer_modified.Transformer(encoder_input_size=2, decoder_input_size=2,\n",
    "                                embedding_size=512, num_heads=8, num_layers=6, feedforward_size=2048).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 The training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer, loss_fn, train_loader, device, print_every):\n",
    "    # Train:\n",
    "    model.train()\n",
    "    train_loss_batches = []\n",
    "\n",
    "    num_batches = len(train_loader)\n",
    "    \n",
    "    for batch_index, (x, y) in enumerate(train_loader, 1):\n",
    "        \n",
    "        feature, target = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model.forward(feature, target)\n",
    "        \n",
    "        loss = loss_fn(predictions.view(X.size(0), -1), target.contiguous().view(X.size(0), -1))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss_batches.append(loss.item())\n",
    "\n",
    "        # If you want to print your progress more often than every epoch you can\n",
    "        # set `print_every` to the number of batches you want between every status update.\n",
    "        # Note that the print out will trigger a full validation on the full val. set => slows down training\n",
    "        if print_every is not None and batch_index % print_every == 0:\n",
    "            model.train()\n",
    "            print(f\"\\tBatch {batch_index}/{num_batches}: \"\n",
    "                  f\"\\tTrain loss: {sum(train_loss_batches[-print_every:])/print_every:.3f}\")\n",
    "\n",
    "    return model, train_loss_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(model, optimizer, loss_fn, train_loader, num_epochs, print_every):\n",
    "    print(\"Starting training\")\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    train_losses = []\n",
    "\n",
    "    for epoch in tqdm(range(1, num_epochs+1)):\n",
    "        model, train_loss = train_epoch(model, optimizer, loss_fn, train_loader, device, print_every)\n",
    "\n",
    "        print(f\"Epoch {epoch}/{num_epochs}: \"\n",
    "              f\"Train loss: {sum(train_loss)/len(train_loss):.3f}\")\n",
    "        \n",
    "        train_losses.extend(train_loss)\n",
    "\n",
    "        if (epoch)%50 == 0:\n",
    "            # Saving model, loss and error log files\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'training_loss': train_loss\n",
    "                }, os.path.join(save_location, 'Transformer_based_channel_model_epoch{}.pth'.format(epoch)))\n",
    "\n",
    "    return model, train_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/chenbingcheng/Library/Python/3.10/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3378, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/06/gmp4cfpd1kn490jzvs864zh00000gn/T/ipykernel_41908/3049097336.py\", line 12, in <module>\n",
      "    Trained_model, train_losses = train_epoch(tf_model, optimizer, loss_fn, train_loader, device, print_every = 1)\n",
      "  File \"/var/folders/06/gmp4cfpd1kn490jzvs864zh00000gn/T/ipykernel_41908/2242708943.py\", line 15, in train_epoch\n",
      "    loss = loss_fn(predictions.view(X.size(0), -1), target.contiguous().view(X.size(0), -1))\n",
      "TypeError: 'int' object is not callable\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/chenbingcheng/Library/Python/3.10/lib/python/site-packages/IPython/core/interactiveshell.py\", line 1997, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/Users/chenbingcheng/Library/Python/3.10/lib/python/site-packages/IPython/core/ultratb.py\", line 1112, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/Users/chenbingcheng/Library/Python/3.10/lib/python/site-packages/IPython/core/ultratb.py\", line 1006, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/Users/chenbingcheng/Library/Python/3.10/lib/python/site-packages/IPython/core/ultratb.py\", line 859, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/Users/chenbingcheng/Library/Python/3.10/lib/python/site-packages/IPython/core/ultratb.py\", line 793, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "  File \"/Users/chenbingcheng/Library/Python/3.10/lib/python/site-packages/IPython/core/ultratb.py\", line 848, in get_records\n",
      "    return list(stack_data.FrameInfo.stack_data(etb, options=options))[tb_offset:]\n",
      "  File \"/Users/chenbingcheng/Library/Python/3.10/lib/python/site-packages/stack_data/core.py\", line 597, in stack_data\n",
      "    yield from collapse_repeated(\n",
      "  File \"/Users/chenbingcheng/Library/Python/3.10/lib/python/site-packages/stack_data/utils.py\", line 84, in collapse_repeated\n",
      "    yield from map(mapper, original_group)\n",
      "  File \"/Users/chenbingcheng/Library/Python/3.10/lib/python/site-packages/stack_data/core.py\", line 587, in mapper\n",
      "    return cls(f, options)\n",
      "  File \"/Users/chenbingcheng/Library/Python/3.10/lib/python/site-packages/stack_data/core.py\", line 551, in __init__\n",
      "    self.executing = Source.executing(frame_or_tb)\n",
      "  File \"/Users/chenbingcheng/Library/Python/3.10/lib/python/site-packages/executing/executing.py\", line 329, in executing\n",
      "    source = cls.for_frame(frame)\n",
      "  File \"/Users/chenbingcheng/Library/Python/3.10/lib/python/site-packages/executing/executing.py\", line 251, in for_frame\n",
      "    return cls.for_filename(frame.f_code.co_filename, frame.f_globals or {}, use_cache)\n",
      "  File \"/Users/chenbingcheng/Library/Python/3.10/lib/python/site-packages/executing/executing.py\", line 279, in for_filename\n",
      "    return cls._for_filename_and_lines(filename, lines)\n",
      "  File \"/Users/chenbingcheng/Library/Python/3.10/lib/python/site-packages/executing/executing.py\", line 289, in _for_filename_and_lines\n",
      "    result = source_cache[(filename, lines)] = cls(filename, lines)\n",
      "  File \"/Users/chenbingcheng/Library/Python/3.10/lib/python/site-packages/stack_data/core.py\", line 97, in __init__\n",
      "    self.asttokens()\n",
      "  File \"/Users/chenbingcheng/Library/Python/3.10/lib/python/site-packages/executing/executing.py\", line 393, in asttokens\n",
      "    return ASTTokens(\n",
      "  File \"/Users/chenbingcheng/Library/Python/3.10/lib/python/site-packages/asttokens/asttokens.py\", line 61, in __init__\n",
      "    source_text = six.ensure_text(source_text)\n",
      "AttributeError: module 'six' has no attribute 'ensure_text'\n"
     ]
    }
   ],
   "source": [
    "# loss function\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# creating optimizer\n",
    "# optimizer = torch.optim.SGD(tf_model.parameters(), lr=1e-4, momentum=0.9, weight_decay=1e-3, nesterov=True)\n",
    "optimizer = torch.optim.Adam(tf_model.parameters(), lr=1e-4)\n",
    "# optimizer = torch.optim.AdamW(tf_model.parameters(), lr=1e-2, betas=(0.9, 0.95), weight_decay=1e-1)\n",
    "\n",
    "# number of epochs \n",
    "num_epochs = 100\n",
    "\n",
    "Trained_model, train_losses = train_epoch(tf_model, optimizer, loss_fn, train_loader, device, print_every = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

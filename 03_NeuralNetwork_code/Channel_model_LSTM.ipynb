{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCC125 - Wireless Link Project - LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import model_LSTM\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import model_Transformer_modified\n",
    "import ast  # Used to parse complex numbers from string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_feature = 'simulation_feature_dataset_processing.csv'\n",
    "output_file_target = 'simulation_target_dataset_processing.csv'\n",
    "\n",
    "# Define a function to parse complex numbers from string\n",
    "def complex_parser(s):\n",
    "    try:\n",
    "        return ast.literal_eval(s)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target = pd.read_csv(output_file_target, header=None, converters={col: complex_parser for col in range(len(pd.read_csv(output_file_target).columns))})\n",
    "\n",
    "df_feature = pd.read_csv(output_file_feature, header=None, converters={col: complex_parser for col in range(len(pd.read_csv(output_file_feature).columns))})\n",
    "\n",
    "# filter zero values rows in the dataframe\n",
    "df_target = df_target[df_target.loc[:,0] != 0j]\n",
    "df_feature = df_feature[df_feature.loc[:,0] != 0j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.574380+0.114876j</td>\n",
       "      <td>0.574380+0.038292j</td>\n",
       "      <td>0.191460+0.038292j</td>\n",
       "      <td>-0.421212+0.497796j</td>\n",
       "      <td>1.110467-0.344628j</td>\n",
       "      <td>-0.344628-1.110467j</td>\n",
       "      <td>-0.804132-0.727548j</td>\n",
       "      <td>-0.804132-0.038292j</td>\n",
       "      <td>0.344628-0.038292j</td>\n",
       "      <td>0.344628-0.114876j</td>\n",
       "      <td>-0.038292+0.497796j</td>\n",
       "      <td>0.574380+0.957299j</td>\n",
       "      <td>-1.187051+0.727548j</td>\n",
       "      <td>0.114876-0.344628j</td>\n",
       "      <td>-0.038292+0.957299j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.880716+0.114876j</td>\n",
       "      <td>0.880716+1.187051j</td>\n",
       "      <td>-0.650964+0.421212j</td>\n",
       "      <td>-0.268044+0.191460j</td>\n",
       "      <td>0.344628-0.268044j</td>\n",
       "      <td>-0.114876+0.650964j</td>\n",
       "      <td>-1.110467-0.344628j</td>\n",
       "      <td>1.033883+0.421212j</td>\n",
       "      <td>-0.497796-0.957299j</td>\n",
       "      <td>0.650964+0.880716j</td>\n",
       "      <td>-0.114876-0.114876j</td>\n",
       "      <td>0.574380-0.268044j</td>\n",
       "      <td>0.650964+0.880716j</td>\n",
       "      <td>-0.727548+0.268044j</td>\n",
       "      <td>0.957299+0.497796j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.421212-0.114876j</td>\n",
       "      <td>-0.114876-0.880716j</td>\n",
       "      <td>-1.033883+0.957299j</td>\n",
       "      <td>0.804132+0.497796j</td>\n",
       "      <td>-0.114876+1.033883j</td>\n",
       "      <td>0.957299+0.191460j</td>\n",
       "      <td>0.191460-1.110467j</td>\n",
       "      <td>0.191460-0.957299j</td>\n",
       "      <td>0.344628+0.727548j</td>\n",
       "      <td>0.574380-0.650964j</td>\n",
       "      <td>0.497796+0.574380j</td>\n",
       "      <td>-0.650964+0.421212j</td>\n",
       "      <td>-1.033883+0.574380j</td>\n",
       "      <td>-0.268044+0.114876j</td>\n",
       "      <td>-0.191460-1.110467j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.574380+0.650964j</td>\n",
       "      <td>0.574380-0.804132j</td>\n",
       "      <td>-0.804132-0.344628j</td>\n",
       "      <td>-0.957299-0.957299j</td>\n",
       "      <td>0.421212+0.804132j</td>\n",
       "      <td>-0.114876+0.650964j</td>\n",
       "      <td>0.038292+0.268044j</td>\n",
       "      <td>0.114876+0.268044j</td>\n",
       "      <td>0.497796-0.574380j</td>\n",
       "      <td>-0.727548+1.110467j</td>\n",
       "      <td>-0.650964+0.268044j</td>\n",
       "      <td>-0.421212+0.344628j</td>\n",
       "      <td>-1.110467+0.804132j</td>\n",
       "      <td>-0.114876+1.187051j</td>\n",
       "      <td>-0.880716+1.187051j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.880716-0.344628j</td>\n",
       "      <td>1.033883+0.804132j</td>\n",
       "      <td>-0.650964-0.421212j</td>\n",
       "      <td>0.268044-0.727548j</td>\n",
       "      <td>-1.110467+0.114876j</td>\n",
       "      <td>-1.187051-1.110467j</td>\n",
       "      <td>0.574380+0.421212j</td>\n",
       "      <td>0.497796+0.421212j</td>\n",
       "      <td>0.880716+0.957299j</td>\n",
       "      <td>-0.574380-0.344628j</td>\n",
       "      <td>-0.038292-0.038292j</td>\n",
       "      <td>-1.033883+0.114876j</td>\n",
       "      <td>-0.421212+1.187051j</td>\n",
       "      <td>-0.191460-0.114876j</td>\n",
       "      <td>-0.344628+0.191460j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>0.574380+0.268044j</td>\n",
       "      <td>0.650964-0.268044j</td>\n",
       "      <td>-1.110467-0.804132j</td>\n",
       "      <td>0.574380-0.574380j</td>\n",
       "      <td>-0.114876+0.268044j</td>\n",
       "      <td>0.804132+0.268044j</td>\n",
       "      <td>-0.804132+0.957299j</td>\n",
       "      <td>1.110467+1.110467j</td>\n",
       "      <td>-0.727548-0.804132j</td>\n",
       "      <td>-1.033883+0.191460j</td>\n",
       "      <td>-0.497796+0.344628j</td>\n",
       "      <td>-0.344628-0.421212j</td>\n",
       "      <td>-0.268044+0.114876j</td>\n",
       "      <td>-0.344628+0.574380j</td>\n",
       "      <td>0.880716+0.114876j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>-0.727548+0.421212j</td>\n",
       "      <td>0.344628+0.114876j</td>\n",
       "      <td>-0.421212+0.574380j</td>\n",
       "      <td>-0.650964-0.650964j</td>\n",
       "      <td>1.033883+0.268044j</td>\n",
       "      <td>1.110467-0.268044j</td>\n",
       "      <td>-1.033883-0.344628j</td>\n",
       "      <td>0.114876-0.650964j</td>\n",
       "      <td>0.038292+0.804132j</td>\n",
       "      <td>0.574380-0.191460j</td>\n",
       "      <td>0.650964-0.804132j</td>\n",
       "      <td>1.187051+0.114876j</td>\n",
       "      <td>0.727548-0.804132j</td>\n",
       "      <td>1.033883+0.344628j</td>\n",
       "      <td>0.114876+0.727548j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>-1.033883-0.497796j</td>\n",
       "      <td>0.421212-0.191460j</td>\n",
       "      <td>0.727548+0.574380j</td>\n",
       "      <td>-0.114876-0.114876j</td>\n",
       "      <td>0.038292+0.268044j</td>\n",
       "      <td>-1.187051+0.497796j</td>\n",
       "      <td>-0.344628-0.650964j</td>\n",
       "      <td>0.727548-0.114876j</td>\n",
       "      <td>-0.344628+0.804132j</td>\n",
       "      <td>-0.038292-0.344628j</td>\n",
       "      <td>-1.033883-0.421212j</td>\n",
       "      <td>0.114876-0.191460j</td>\n",
       "      <td>-0.038292-1.033883j</td>\n",
       "      <td>0.497796-0.191460j</td>\n",
       "      <td>-0.268044+0.344628j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>-1.033883+0.114876j</td>\n",
       "      <td>0.957299-0.804132j</td>\n",
       "      <td>-0.191460-0.574380j</td>\n",
       "      <td>0.804132-1.110467j</td>\n",
       "      <td>0.344628+0.038292j</td>\n",
       "      <td>-0.497796+0.421212j</td>\n",
       "      <td>-0.344628-0.727548j</td>\n",
       "      <td>-0.268044-0.038292j</td>\n",
       "      <td>-1.110467+0.727548j</td>\n",
       "      <td>0.421212+0.344628j</td>\n",
       "      <td>0.114876-0.957299j</td>\n",
       "      <td>1.187051-0.650964j</td>\n",
       "      <td>-1.033883+0.191460j</td>\n",
       "      <td>-1.110467+0.957299j</td>\n",
       "      <td>-0.957299-0.574380j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>-0.880716-1.033883j</td>\n",
       "      <td>1.033883+0.804132j</td>\n",
       "      <td>-1.187051-0.344628j</td>\n",
       "      <td>0.344628+1.110467j</td>\n",
       "      <td>-0.727548+0.114876j</td>\n",
       "      <td>1.110467+0.804132j</td>\n",
       "      <td>-1.110467+0.574380j</td>\n",
       "      <td>-0.038292-0.344628j</td>\n",
       "      <td>-0.038292-1.187051j</td>\n",
       "      <td>-0.880716+0.880716j</td>\n",
       "      <td>0.421212-1.110467j</td>\n",
       "      <td>-0.038292-0.957299j</td>\n",
       "      <td>1.187051-0.574380j</td>\n",
       "      <td>0.344628-0.727548j</td>\n",
       "      <td>0.114876+1.033883j</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0                   1                   2   \\\n",
       "0      0.574380+0.114876j  0.574380+0.038292j  0.191460+0.038292j   \n",
       "1     -0.880716+0.114876j  0.880716+1.187051j -0.650964+0.421212j   \n",
       "2      0.421212-0.114876j -0.114876-0.880716j -1.033883+0.957299j   \n",
       "3      0.574380+0.650964j  0.574380-0.804132j -0.804132-0.344628j   \n",
       "4     -0.880716-0.344628j  1.033883+0.804132j -0.650964-0.421212j   \n",
       "...                   ...                 ...                 ...   \n",
       "29995  0.574380+0.268044j  0.650964-0.268044j -1.110467-0.804132j   \n",
       "29996 -0.727548+0.421212j  0.344628+0.114876j -0.421212+0.574380j   \n",
       "29997 -1.033883-0.497796j  0.421212-0.191460j  0.727548+0.574380j   \n",
       "29998 -1.033883+0.114876j  0.957299-0.804132j -0.191460-0.574380j   \n",
       "29999 -0.880716-1.033883j  1.033883+0.804132j -1.187051-0.344628j   \n",
       "\n",
       "                       3                   4                   5   \\\n",
       "0     -0.421212+0.497796j  1.110467-0.344628j -0.344628-1.110467j   \n",
       "1     -0.268044+0.191460j  0.344628-0.268044j -0.114876+0.650964j   \n",
       "2      0.804132+0.497796j -0.114876+1.033883j  0.957299+0.191460j   \n",
       "3     -0.957299-0.957299j  0.421212+0.804132j -0.114876+0.650964j   \n",
       "4      0.268044-0.727548j -1.110467+0.114876j -1.187051-1.110467j   \n",
       "...                   ...                 ...                 ...   \n",
       "29995  0.574380-0.574380j -0.114876+0.268044j  0.804132+0.268044j   \n",
       "29996 -0.650964-0.650964j  1.033883+0.268044j  1.110467-0.268044j   \n",
       "29997 -0.114876-0.114876j  0.038292+0.268044j -1.187051+0.497796j   \n",
       "29998  0.804132-1.110467j  0.344628+0.038292j -0.497796+0.421212j   \n",
       "29999  0.344628+1.110467j -0.727548+0.114876j  1.110467+0.804132j   \n",
       "\n",
       "                       6                   7                   8   \\\n",
       "0     -0.804132-0.727548j -0.804132-0.038292j  0.344628-0.038292j   \n",
       "1     -1.110467-0.344628j  1.033883+0.421212j -0.497796-0.957299j   \n",
       "2      0.191460-1.110467j  0.191460-0.957299j  0.344628+0.727548j   \n",
       "3      0.038292+0.268044j  0.114876+0.268044j  0.497796-0.574380j   \n",
       "4      0.574380+0.421212j  0.497796+0.421212j  0.880716+0.957299j   \n",
       "...                   ...                 ...                 ...   \n",
       "29995 -0.804132+0.957299j  1.110467+1.110467j -0.727548-0.804132j   \n",
       "29996 -1.033883-0.344628j  0.114876-0.650964j  0.038292+0.804132j   \n",
       "29997 -0.344628-0.650964j  0.727548-0.114876j -0.344628+0.804132j   \n",
       "29998 -0.344628-0.727548j -0.268044-0.038292j -1.110467+0.727548j   \n",
       "29999 -1.110467+0.574380j -0.038292-0.344628j -0.038292-1.187051j   \n",
       "\n",
       "                       9                   10                  11  \\\n",
       "0      0.344628-0.114876j -0.038292+0.497796j  0.574380+0.957299j   \n",
       "1      0.650964+0.880716j -0.114876-0.114876j  0.574380-0.268044j   \n",
       "2      0.574380-0.650964j  0.497796+0.574380j -0.650964+0.421212j   \n",
       "3     -0.727548+1.110467j -0.650964+0.268044j -0.421212+0.344628j   \n",
       "4     -0.574380-0.344628j -0.038292-0.038292j -1.033883+0.114876j   \n",
       "...                   ...                 ...                 ...   \n",
       "29995 -1.033883+0.191460j -0.497796+0.344628j -0.344628-0.421212j   \n",
       "29996  0.574380-0.191460j  0.650964-0.804132j  1.187051+0.114876j   \n",
       "29997 -0.038292-0.344628j -1.033883-0.421212j  0.114876-0.191460j   \n",
       "29998  0.421212+0.344628j  0.114876-0.957299j  1.187051-0.650964j   \n",
       "29999 -0.880716+0.880716j  0.421212-1.110467j -0.038292-0.957299j   \n",
       "\n",
       "                       12                  13                  14  \n",
       "0     -1.187051+0.727548j  0.114876-0.344628j -0.038292+0.957299j  \n",
       "1      0.650964+0.880716j -0.727548+0.268044j  0.957299+0.497796j  \n",
       "2     -1.033883+0.574380j -0.268044+0.114876j -0.191460-1.110467j  \n",
       "3     -1.110467+0.804132j -0.114876+1.187051j -0.880716+1.187051j  \n",
       "4     -0.421212+1.187051j -0.191460-0.114876j -0.344628+0.191460j  \n",
       "...                   ...                 ...                 ...  \n",
       "29995 -0.268044+0.114876j -0.344628+0.574380j  0.880716+0.114876j  \n",
       "29996  0.727548-0.804132j  1.033883+0.344628j  0.114876+0.727548j  \n",
       "29997 -0.038292-1.033883j  0.497796-0.191460j -0.268044+0.344628j  \n",
       "29998 -1.033883+0.191460j -1.110467+0.957299j -0.957299-0.574380j  \n",
       "29999  1.187051-0.574380j  0.344628-0.727548j  0.114876+1.033883j  \n",
       "\n",
       "[30000 rows x 15 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>465</th>\n",
       "      <th>466</th>\n",
       "      <th>467</th>\n",
       "      <th>468</th>\n",
       "      <th>469</th>\n",
       "      <th>470</th>\n",
       "      <th>471</th>\n",
       "      <th>472</th>\n",
       "      <th>473</th>\n",
       "      <th>474</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.245799-0.292176j</td>\n",
       "      <td>-1.330345-0.318523j</td>\n",
       "      <td>-1.333179-0.327656j</td>\n",
       "      <td>-1.295741-0.327539j</td>\n",
       "      <td>-1.257863-0.325232j</td>\n",
       "      <td>-1.242229-0.324840j</td>\n",
       "      <td>-1.249740-0.327369j</td>\n",
       "      <td>-1.265334-0.330762j</td>\n",
       "      <td>-1.270650-0.331395j</td>\n",
       "      <td>-1.258896-0.326735j</td>\n",
       "      <td>...</td>\n",
       "      <td>0.223757-0.379588j</td>\n",
       "      <td>0.244452-0.201714j</td>\n",
       "      <td>0.092920+0.175302j</td>\n",
       "      <td>-0.114768+0.635493j</td>\n",
       "      <td>-0.277130+1.017293j</td>\n",
       "      <td>-0.343242+1.189098j</td>\n",
       "      <td>-0.315785+1.108918j</td>\n",
       "      <td>-0.231035+0.835668j</td>\n",
       "      <td>-0.132680+0.489787j</td>\n",
       "      <td>-0.052745+0.190412j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.106911+0.491718j</td>\n",
       "      <td>1.177100+0.521656j</td>\n",
       "      <td>1.172034+0.520385j</td>\n",
       "      <td>1.131914+0.507528j</td>\n",
       "      <td>1.095133+0.499688j</td>\n",
       "      <td>1.082941+0.503957j</td>\n",
       "      <td>1.095336+0.517099j</td>\n",
       "      <td>1.116791+0.529557j</td>\n",
       "      <td>1.128315+0.531811j</td>\n",
       "      <td>1.121248+0.520812j</td>\n",
       "      <td>...</td>\n",
       "      <td>0.951374+0.052800j</td>\n",
       "      <td>0.759483-0.036866j</td>\n",
       "      <td>0.339731-0.312025j</td>\n",
       "      <td>-0.170124-0.652597j</td>\n",
       "      <td>-0.597819-0.921273j</td>\n",
       "      <td>-0.816160-1.019368j</td>\n",
       "      <td>-0.794928-0.922378j</td>\n",
       "      <td>-0.599373-0.680918j</td>\n",
       "      <td>-0.342885-0.389879j</td>\n",
       "      <td>-0.126636-0.142680j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.018773+1.244856j</td>\n",
       "      <td>0.021368+1.319193j</td>\n",
       "      <td>0.024165+1.313594j</td>\n",
       "      <td>0.023490+1.275121j</td>\n",
       "      <td>0.018128+1.244869j</td>\n",
       "      <td>0.010646+1.241904j</td>\n",
       "      <td>0.005653+1.261579j</td>\n",
       "      <td>0.006373+1.284680j</td>\n",
       "      <td>0.012243+1.291802j</td>\n",
       "      <td>0.018959+1.277444j</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140435+0.337597j</td>\n",
       "      <td>-0.133219+0.260295j</td>\n",
       "      <td>-0.506815+0.242203j</td>\n",
       "      <td>-0.917298+0.242280j</td>\n",
       "      <td>-1.249729+0.230142j</td>\n",
       "      <td>-1.389536+0.196261j</td>\n",
       "      <td>-1.283955+0.146636j</td>\n",
       "      <td>-0.973925+0.091823j</td>\n",
       "      <td>-0.575025+0.040488j</td>\n",
       "      <td>-0.219282-0.000987j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.295474-0.280640j</td>\n",
       "      <td>1.375535-0.299172j</td>\n",
       "      <td>1.371563-0.299915j</td>\n",
       "      <td>1.331481-0.291760j</td>\n",
       "      <td>1.298031-0.283309j</td>\n",
       "      <td>1.291666-0.280071j</td>\n",
       "      <td>1.308322-0.283263j</td>\n",
       "      <td>1.329003-0.290310j</td>\n",
       "      <td>1.335002-0.297024j</td>\n",
       "      <td>1.322205-0.300643j</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.129886-1.593995j</td>\n",
       "      <td>-0.059573-1.652626j</td>\n",
       "      <td>0.190969-1.739536j</td>\n",
       "      <td>0.509871-1.828353j</td>\n",
       "      <td>0.767413-1.860173j</td>\n",
       "      <td>0.870409-1.767205j</td>\n",
       "      <td>0.795386-1.512713j</td>\n",
       "      <td>0.587682-1.121238j</td>\n",
       "      <td>0.331428-0.676545j</td>\n",
       "      <td>0.108752-0.284741j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.802838-0.766358j</td>\n",
       "      <td>-0.852347-0.813439j</td>\n",
       "      <td>-0.847930-0.812228j</td>\n",
       "      <td>-0.820891-0.790825j</td>\n",
       "      <td>-0.799941-0.773245j</td>\n",
       "      <td>-0.799005-0.770460j</td>\n",
       "      <td>-0.814688-0.779914j</td>\n",
       "      <td>-0.832167-0.790823j</td>\n",
       "      <td>-0.836501-0.792250j</td>\n",
       "      <td>-0.823647-0.781384j</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087930-0.242369j</td>\n",
       "      <td>-0.068578-0.280977j</td>\n",
       "      <td>-0.157946-0.247598j</td>\n",
       "      <td>-0.289956-0.190257j</td>\n",
       "      <td>-0.395097-0.141364j</td>\n",
       "      <td>-0.429473-0.108417j</td>\n",
       "      <td>-0.386520-0.082776j</td>\n",
       "      <td>-0.290129-0.055175j</td>\n",
       "      <td>-0.177237-0.025308j</td>\n",
       "      <td>-0.080350-0.000589j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>-0.591411-0.946587j</td>\n",
       "      <td>-0.631333-1.003882j</td>\n",
       "      <td>-0.632693-0.998537j</td>\n",
       "      <td>-0.615195-0.966185j</td>\n",
       "      <td>-0.596590-0.939667j</td>\n",
       "      <td>-0.586312-0.935106j</td>\n",
       "      <td>-0.584751-0.948876j</td>\n",
       "      <td>-0.586570-0.964652j</td>\n",
       "      <td>-0.585496-0.966410j</td>\n",
       "      <td>-0.579427-0.950975j</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.745403-0.004432j</td>\n",
       "      <td>-0.603040+0.153681j</td>\n",
       "      <td>-0.333364+0.382821j</td>\n",
       "      <td>-0.013515+0.632996j</td>\n",
       "      <td>0.257330+0.827564j</td>\n",
       "      <td>0.404964+0.897226j</td>\n",
       "      <td>0.411455+0.815245j</td>\n",
       "      <td>0.314687+0.612213j</td>\n",
       "      <td>0.180684+0.361055j</td>\n",
       "      <td>0.067738+0.140979j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>1.414226-0.558196j</td>\n",
       "      <td>1.500999-0.596972j</td>\n",
       "      <td>1.492131-0.602040j</td>\n",
       "      <td>1.437303-0.592868j</td>\n",
       "      <td>1.383923-0.585465j</td>\n",
       "      <td>1.359225-0.585929j</td>\n",
       "      <td>1.364790-0.590859j</td>\n",
       "      <td>1.383077-0.592651j</td>\n",
       "      <td>1.391935-0.585949j</td>\n",
       "      <td>1.381941-0.572388j</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.675473+0.076402j</td>\n",
       "      <td>-1.568001-0.163546j</td>\n",
       "      <td>-1.316565-0.408754j</td>\n",
       "      <td>-1.014707-0.661175j</td>\n",
       "      <td>-0.744910-0.870518j</td>\n",
       "      <td>-0.544256-0.962972j</td>\n",
       "      <td>-0.402459-0.892619j</td>\n",
       "      <td>-0.287181-0.677981j</td>\n",
       "      <td>-0.175038-0.397339j</td>\n",
       "      <td>-0.067040-0.147374j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>0.722211-1.194098j</td>\n",
       "      <td>0.766435-1.271573j</td>\n",
       "      <td>0.760854-1.273961j</td>\n",
       "      <td>0.735113-1.245743j</td>\n",
       "      <td>0.714173-1.224247j</td>\n",
       "      <td>0.708246-1.225443j</td>\n",
       "      <td>0.713131-1.243518j</td>\n",
       "      <td>0.717808-1.260203j</td>\n",
       "      <td>0.714080-1.258104j</td>\n",
       "      <td>0.703292-1.233477j</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.105733+0.736649j</td>\n",
       "      <td>-0.217215+0.551022j</td>\n",
       "      <td>-0.246886+0.251756j</td>\n",
       "      <td>-0.244449-0.097723j</td>\n",
       "      <td>-0.239509-0.398960j</td>\n",
       "      <td>-0.232995-0.565116j</td>\n",
       "      <td>-0.210805-0.563894j</td>\n",
       "      <td>-0.164268-0.430281j</td>\n",
       "      <td>-0.101104-0.242452j</td>\n",
       "      <td>-0.040537-0.078296j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>0.749197+1.069434j</td>\n",
       "      <td>0.793965+1.148567j</td>\n",
       "      <td>0.792032+1.157250j</td>\n",
       "      <td>0.771860+1.130366j</td>\n",
       "      <td>0.757186+1.101022j</td>\n",
       "      <td>0.757277+1.087773j</td>\n",
       "      <td>0.766513+1.091279j</td>\n",
       "      <td>0.771764+1.099125j</td>\n",
       "      <td>0.762402+1.096343j</td>\n",
       "      <td>0.738889+1.077893j</td>\n",
       "      <td>...</td>\n",
       "      <td>1.846746+0.453473j</td>\n",
       "      <td>1.664992+0.588680j</td>\n",
       "      <td>1.291616+0.852089j</td>\n",
       "      <td>0.824895+1.155062j</td>\n",
       "      <td>0.401593+1.383355j</td>\n",
       "      <td>0.122026+1.440803j</td>\n",
       "      <td>0.004537+1.290577j</td>\n",
       "      <td>-0.004731+0.972788j</td>\n",
       "      <td>0.017895+0.586556j</td>\n",
       "      <td>0.022631+0.244009j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>0.954786+0.770151j</td>\n",
       "      <td>1.012539+0.811824j</td>\n",
       "      <td>1.005158+0.807281j</td>\n",
       "      <td>0.968209+0.784296j</td>\n",
       "      <td>0.935026+0.765948j</td>\n",
       "      <td>0.923357+0.762145j</td>\n",
       "      <td>0.932256+0.769557j</td>\n",
       "      <td>0.947737+0.777538j</td>\n",
       "      <td>0.953757+0.776451j</td>\n",
       "      <td>0.944128+0.765273j</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.862934+0.455498j</td>\n",
       "      <td>-0.595929+0.258505j</td>\n",
       "      <td>-0.254154-0.118325j</td>\n",
       "      <td>0.120527-0.555753j</td>\n",
       "      <td>0.441699-0.907743j</td>\n",
       "      <td>0.621632-1.062517j</td>\n",
       "      <td>0.621813-0.988103j</td>\n",
       "      <td>0.475748-0.740069j</td>\n",
       "      <td>0.269149-0.428069j</td>\n",
       "      <td>0.092172-0.160869j</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 475 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0                   1                   2    \\\n",
       "0     -1.245799-0.292176j -1.330345-0.318523j -1.333179-0.327656j   \n",
       "1      1.106911+0.491718j  1.177100+0.521656j  1.172034+0.520385j   \n",
       "2      0.018773+1.244856j  0.021368+1.319193j  0.024165+1.313594j   \n",
       "3      1.295474-0.280640j  1.375535-0.299172j  1.371563-0.299915j   \n",
       "4     -0.802838-0.766358j -0.852347-0.813439j -0.847930-0.812228j   \n",
       "...                   ...                 ...                 ...   \n",
       "29995 -0.591411-0.946587j -0.631333-1.003882j -0.632693-0.998537j   \n",
       "29996  1.414226-0.558196j  1.500999-0.596972j  1.492131-0.602040j   \n",
       "29997  0.722211-1.194098j  0.766435-1.271573j  0.760854-1.273961j   \n",
       "29998  0.749197+1.069434j  0.793965+1.148567j  0.792032+1.157250j   \n",
       "29999  0.954786+0.770151j  1.012539+0.811824j  1.005158+0.807281j   \n",
       "\n",
       "                      3                   4                   5    \\\n",
       "0     -1.295741-0.327539j -1.257863-0.325232j -1.242229-0.324840j   \n",
       "1      1.131914+0.507528j  1.095133+0.499688j  1.082941+0.503957j   \n",
       "2      0.023490+1.275121j  0.018128+1.244869j  0.010646+1.241904j   \n",
       "3      1.331481-0.291760j  1.298031-0.283309j  1.291666-0.280071j   \n",
       "4     -0.820891-0.790825j -0.799941-0.773245j -0.799005-0.770460j   \n",
       "...                   ...                 ...                 ...   \n",
       "29995 -0.615195-0.966185j -0.596590-0.939667j -0.586312-0.935106j   \n",
       "29996  1.437303-0.592868j  1.383923-0.585465j  1.359225-0.585929j   \n",
       "29997  0.735113-1.245743j  0.714173-1.224247j  0.708246-1.225443j   \n",
       "29998  0.771860+1.130366j  0.757186+1.101022j  0.757277+1.087773j   \n",
       "29999  0.968209+0.784296j  0.935026+0.765948j  0.923357+0.762145j   \n",
       "\n",
       "                      6                   7                   8    \\\n",
       "0     -1.249740-0.327369j -1.265334-0.330762j -1.270650-0.331395j   \n",
       "1      1.095336+0.517099j  1.116791+0.529557j  1.128315+0.531811j   \n",
       "2      0.005653+1.261579j  0.006373+1.284680j  0.012243+1.291802j   \n",
       "3      1.308322-0.283263j  1.329003-0.290310j  1.335002-0.297024j   \n",
       "4     -0.814688-0.779914j -0.832167-0.790823j -0.836501-0.792250j   \n",
       "...                   ...                 ...                 ...   \n",
       "29995 -0.584751-0.948876j -0.586570-0.964652j -0.585496-0.966410j   \n",
       "29996  1.364790-0.590859j  1.383077-0.592651j  1.391935-0.585949j   \n",
       "29997  0.713131-1.243518j  0.717808-1.260203j  0.714080-1.258104j   \n",
       "29998  0.766513+1.091279j  0.771764+1.099125j  0.762402+1.096343j   \n",
       "29999  0.932256+0.769557j  0.947737+0.777538j  0.953757+0.776451j   \n",
       "\n",
       "                      9    ...                 465                 466  \\\n",
       "0     -1.258896-0.326735j  ...  0.223757-0.379588j  0.244452-0.201714j   \n",
       "1      1.121248+0.520812j  ...  0.951374+0.052800j  0.759483-0.036866j   \n",
       "2      0.018959+1.277444j  ...  0.140435+0.337597j -0.133219+0.260295j   \n",
       "3      1.322205-0.300643j  ... -0.129886-1.593995j -0.059573-1.652626j   \n",
       "4     -0.823647-0.781384j  ... -0.087930-0.242369j -0.068578-0.280977j   \n",
       "...                   ...  ...                 ...                 ...   \n",
       "29995 -0.579427-0.950975j  ... -0.745403-0.004432j -0.603040+0.153681j   \n",
       "29996  1.381941-0.572388j  ... -1.675473+0.076402j -1.568001-0.163546j   \n",
       "29997  0.703292-1.233477j  ... -0.105733+0.736649j -0.217215+0.551022j   \n",
       "29998  0.738889+1.077893j  ...  1.846746+0.453473j  1.664992+0.588680j   \n",
       "29999  0.944128+0.765273j  ... -0.862934+0.455498j -0.595929+0.258505j   \n",
       "\n",
       "                      467                 468                 469  \\\n",
       "0      0.092920+0.175302j -0.114768+0.635493j -0.277130+1.017293j   \n",
       "1      0.339731-0.312025j -0.170124-0.652597j -0.597819-0.921273j   \n",
       "2     -0.506815+0.242203j -0.917298+0.242280j -1.249729+0.230142j   \n",
       "3      0.190969-1.739536j  0.509871-1.828353j  0.767413-1.860173j   \n",
       "4     -0.157946-0.247598j -0.289956-0.190257j -0.395097-0.141364j   \n",
       "...                   ...                 ...                 ...   \n",
       "29995 -0.333364+0.382821j -0.013515+0.632996j  0.257330+0.827564j   \n",
       "29996 -1.316565-0.408754j -1.014707-0.661175j -0.744910-0.870518j   \n",
       "29997 -0.246886+0.251756j -0.244449-0.097723j -0.239509-0.398960j   \n",
       "29998  1.291616+0.852089j  0.824895+1.155062j  0.401593+1.383355j   \n",
       "29999 -0.254154-0.118325j  0.120527-0.555753j  0.441699-0.907743j   \n",
       "\n",
       "                      470                 471                 472  \\\n",
       "0     -0.343242+1.189098j -0.315785+1.108918j -0.231035+0.835668j   \n",
       "1     -0.816160-1.019368j -0.794928-0.922378j -0.599373-0.680918j   \n",
       "2     -1.389536+0.196261j -1.283955+0.146636j -0.973925+0.091823j   \n",
       "3      0.870409-1.767205j  0.795386-1.512713j  0.587682-1.121238j   \n",
       "4     -0.429473-0.108417j -0.386520-0.082776j -0.290129-0.055175j   \n",
       "...                   ...                 ...                 ...   \n",
       "29995  0.404964+0.897226j  0.411455+0.815245j  0.314687+0.612213j   \n",
       "29996 -0.544256-0.962972j -0.402459-0.892619j -0.287181-0.677981j   \n",
       "29997 -0.232995-0.565116j -0.210805-0.563894j -0.164268-0.430281j   \n",
       "29998  0.122026+1.440803j  0.004537+1.290577j -0.004731+0.972788j   \n",
       "29999  0.621632-1.062517j  0.621813-0.988103j  0.475748-0.740069j   \n",
       "\n",
       "                      473                 474  \n",
       "0     -0.132680+0.489787j -0.052745+0.190412j  \n",
       "1     -0.342885-0.389879j -0.126636-0.142680j  \n",
       "2     -0.575025+0.040488j -0.219282-0.000987j  \n",
       "3      0.331428-0.676545j  0.108752-0.284741j  \n",
       "4     -0.177237-0.025308j -0.080350-0.000589j  \n",
       "...                   ...                 ...  \n",
       "29995  0.180684+0.361055j  0.067738+0.140979j  \n",
       "29996 -0.175038-0.397339j -0.067040-0.147374j  \n",
       "29997 -0.101104-0.242452j -0.040537-0.078296j  \n",
       "29998  0.017895+0.586556j  0.022631+0.244009j  \n",
       "29999  0.269149-0.428069j  0.092172-0.160869j  \n",
       "\n",
       "[30000 rows x 475 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_symbol = df_target.to_numpy()\n",
    "\n",
    "real_target_symbol = np.real(target_symbol)\n",
    "imag_target_symbol = np.imag(target_symbol)\n",
    "\n",
    "y = np.array([real_target_symbol, imag_target_symbol]).transpose(1, 2, 0)\n",
    "\n",
    "\n",
    "feature_symbol = df_feature.to_numpy()\n",
    "real_feature_symbol = np.real(feature_symbol)\n",
    "imag_feature_symbol = np.imag(feature_symbol)\n",
    "\n",
    "X = np.array([real_feature_symbol, imag_feature_symbol]).transpose(1, 2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 475, 2)\n",
      "(30000, 15, 2)\n",
      "30000\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SymbolDataset(Dataset):\n",
    "    \"\"\"Class to create the torch Dataset object\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y):\n",
    "        super(SymbolDataset, self).__init__()\n",
    "\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"Total number of samples\"\"\"\n",
    "        return len(self.X[:,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining batch size\n",
    "batch_size = 32\n",
    "\n",
    "# creating torch dataset and dataloaders\n",
    "symbol_dataset = SymbolDataset(X,y)\n",
    "train_loader = DataLoader(symbol_dataset, batch_size, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining model save location\n",
    "save_location = \"./LSTM_models\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "LSTM_model = model_LSTM.LSTM(input_size=2, input_seq_len=475,\n",
    "                             hidden_size=128, num_layers=3, output_size=2, output_seq_len=15).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (LSTM_first_layer): ModuleList(\n",
       "    (0): LSTMCell(\n",
       "      (W_hh): Linear(in_features=128, out_features=512, bias=True)\n",
       "      (W_xh): Linear(in_features=2, out_features=512, bias=True)\n",
       "    )\n",
       "    (1-2): 2 x LSTMCell(\n",
       "      (W_hh): Linear(in_features=128, out_features=512, bias=True)\n",
       "      (W_xh): Linear(in_features=128, out_features=512, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (LSTM_whole): ModuleList(\n",
       "    (0): LSTMCell(\n",
       "      (W_hh): Linear(in_features=128, out_features=512, bias=True)\n",
       "      (W_xh): Linear(in_features=2, out_features=512, bias=True)\n",
       "    )\n",
       "    (1-2): 2 x LSTMCell(\n",
       "      (W_hh): Linear(in_features=128, out_features=512, bias=True)\n",
       "      (W_xh): Linear(in_features=128, out_features=512, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=60800, out_features=30, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTM_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 The training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [14:04<23:13:26, 844.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100....Training loss = 0.4990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 2/100 [28:06<22:56:36, 842.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100....Training loss = 0.4988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 3/100 [42:10<22:43:22, 843.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100....Training loss = 0.4080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 4/100 [56:19<22:33:05, 845.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100....Training loss = 0.0113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 5/100 [1:10:28<22:20:46, 846.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100....Training loss = 0.0066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 6/100 [1:24:36<22:07:15, 847.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100....Training loss = 0.0063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 7/100 [1:38:45<21:54:02, 847.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100....Training loss = 0.0062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 8/100 [1:52:52<21:39:52, 847.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100....Training loss = 0.0060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 9/100 [2:07:02<21:26:43, 848.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100....Training loss = 0.0062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 10/100 [2:21:11<21:12:45, 848.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100....Training loss = 0.0060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 11/100 [2:35:19<20:58:15, 848.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100....Training loss = 0.0058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 12/100 [2:49:17<20:39:52, 845.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100....Training loss = 0.0060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 13/100 [3:02:19<19:57:46, 826.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100....Training loss = 0.0057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 14/100 [3:15:10<19:20:19, 809.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100....Training loss = 0.0047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 15/100 [3:28:04<18:51:25, 798.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100....Training loss = 0.0030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 16/100 [3:41:00<18:28:31, 791.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100....Training loss = 0.0026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 17/100 [3:53:56<18:08:57, 787.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100....Training loss = 0.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 18/100 [4:06:51<17:50:59, 783.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100....Training loss = 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 19/100 [4:19:48<17:35:01, 781.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100....Training loss = 0.0021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 20/100 [4:32:45<17:20:06, 780.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100....Training loss = 0.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 21/100 [4:45:42<17:05:59, 779.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100....Training loss = 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 22/100 [4:58:37<16:51:25, 778.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100....Training loss = 0.0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 23/100 [5:11:35<16:38:29, 778.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100....Training loss = 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 24/100 [5:24:32<16:24:55, 777.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100....Training loss = 0.0021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 25/100 [5:37:28<16:11:34, 777.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100....Training loss = 0.0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 26/100 [5:50:27<15:59:03, 777.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100....Training loss = 0.0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 27/100 [6:03:25<15:46:22, 777.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100....Training loss = 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 28/100 [6:16:22<15:32:57, 777.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100....Training loss = 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 29/100 [6:29:15<15:18:29, 776.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100....Training loss = 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 30/100 [6:42:09<15:04:54, 775.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100....Training loss = 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███       | 31/100 [6:55:03<14:51:13, 774.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100....Training loss = 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 32/100 [7:07:54<14:37:08, 773.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100....Training loss = 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 33/100 [7:20:45<14:23:17, 773.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100....Training loss = 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▍      | 34/100 [7:33:38<14:10:19, 773.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/100....Training loss = 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 35/100 [7:46:31<13:57:26, 773.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/100....Training loss = 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 36/100 [7:59:24<13:44:26, 772.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100....Training loss = 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 37/100 [8:12:21<13:32:53, 774.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/100....Training loss = 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 38/100 [8:25:18<13:20:46, 774.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100....Training loss = 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███▉      | 39/100 [8:38:15<13:08:41, 775.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/100....Training loss = 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 40/100 [8:51:10<12:55:31, 775.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100....Training loss = 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████      | 41/100 [9:04:07<12:42:53, 775.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100....Training loss = 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 42/100 [9:17:03<12:29:54, 775.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/100....Training loss = 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 43/100 [9:29:54<12:15:43, 774.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/100....Training loss = 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 44/100 [9:42:45<12:01:47, 773.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/100....Training loss = 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 45/100 [9:56:36<12:04:44, 790.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100....Training loss = 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 46/100 [10:10:08<11:57:28, 797.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/100....Training loss = 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 47/100 [10:23:42<11:48:30, 802.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/100....Training loss = 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 48/100 [10:37:13<11:37:27, 804.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/100....Training loss = 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|████▉     | 49/100 [10:50:36<11:23:38, 804.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100....Training loss = 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 50/100 [11:04:13<11:13:30, 808.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100....Training loss = 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|█████     | 51/100 [11:17:33<10:57:56, 805.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100....Training loss = 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 53/100 [11:43:28<10:19:44, 791.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/100....Training loss = 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 54/100 [11:56:25<10:03:24, 787.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/100....Training loss = 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▌    | 55/100 [12:09:30<9:49:49, 786.43s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100....Training loss = 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 56/100 [12:22:35<9:36:21, 785.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100....Training loss = 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 57/100 [12:35:31<9:21:06, 782.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100....Training loss = 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 58/100 [12:48:31<9:07:24, 782.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100....Training loss = 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████▉    | 59/100 [13:01:33<8:54:23, 782.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100....Training loss = 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 60/100 [13:14:39<8:42:06, 783.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100....Training loss = 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|██████    | 61/100 [13:27:44<8:29:22, 783.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100....Training loss = 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 62/100 [13:40:47<8:16:20, 783.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100....Training loss = 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 63/100 [13:53:57<8:04:26, 785.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/100....Training loss = 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▍   | 64/100 [14:07:08<7:52:19, 787.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/100....Training loss = 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 65/100 [14:20:15<7:39:02, 786.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100....Training loss = 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▌   | 66/100 [14:33:20<7:25:35, 786.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/100....Training loss = 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 67/100 [14:46:25<7:12:19, 786.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/100....Training loss = 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 68/100 [14:59:30<6:59:00, 785.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/100....Training loss = 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████▉   | 69/100 [15:12:38<6:46:23, 786.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/100....Training loss = 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 70/100 [15:26:03<6:35:59, 791.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/100....Training loss = 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████   | 71/100 [15:39:13<6:22:30, 791.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/100....Training loss = 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 72/100 [15:52:17<6:08:17, 789.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100....Training loss = 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 73/100 [16:05:35<5:56:19, 791.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100....Training loss = 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▍  | 74/100 [16:18:38<5:42:01, 789.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/100....Training loss = 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 75/100 [16:31:39<5:27:47, 786.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/100....Training loss = 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 76/100 [16:44:39<5:13:50, 784.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100....Training loss = 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 77/100 [16:57:41<5:00:27, 783.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/100....Training loss = 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 78/100 [17:10:45<4:47:29, 784.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/100....Training loss = 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▉  | 79/100 [17:23:44<4:33:47, 782.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/100....Training loss = 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 80/100 [17:36:47<4:20:53, 782.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100....Training loss = 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████  | 81/100 [17:49:50<4:07:49, 782.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100....Training loss = 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 82/100 [18:02:51<3:54:41, 782.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/100....Training loss = 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 83/100 [18:15:52<3:41:33, 781.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/100....Training loss = 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▍ | 84/100 [18:28:58<3:28:48, 783.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/100....Training loss = 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 85/100 [18:42:05<3:16:01, 784.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/100....Training loss = 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▌ | 86/100 [18:55:22<3:03:53, 788.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/100....Training loss = 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████▋ | 87/100 [19:08:39<2:51:19, 790.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/100....Training loss = 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 88/100 [19:21:52<2:38:16, 791.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/100....Training loss = 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▉ | 89/100 [19:35:09<2:25:23, 793.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/100....Training loss = 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 90/100 [19:48:20<2:12:06, 792.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/100....Training loss = 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████ | 91/100 [20:02:07<2:00:26, 802.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/100....Training loss = 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 92/100 [20:16:56<1:50:28, 828.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/100....Training loss = 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 93/100 [20:31:37<1:38:30, 844.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/100....Training loss = 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 94/100 [20:46:19<1:25:34, 855.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/100....Training loss = 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 95/100 [21:00:52<1:11:44, 860.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/100....Training loss = 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 96/100 [21:15:07<57:16, 859.16s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/100....Training loss = 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████▋| 97/100 [21:29:00<42:33, 851.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100....Training loss = 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 98/100 [21:42:14<27:47, 833.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/100....Training loss = 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████▉| 99/100 [21:54:44<13:28, 808.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/100....Training loss = 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [22:07:17<00:00, 796.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100....Training loss = 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# number of epochs\n",
    "epochs = 100\n",
    "\n",
    "# metric variables\n",
    "training_loss = []\n",
    "validation_loss = []\n",
    "val_mad = []\n",
    "val_fad = []\n",
    "\n",
    "# Define the MSE loss function\n",
    "criterion = nn.MSELoss().float()\n",
    "\n",
    "learning_rate = 0.0001\n",
    "# optimizer = torch.optim.SGD(LSTM_model.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.Adam(LSTM_model.parameters(), lr=learning_rate)\n",
    "# optimizer = torch.optim.AdamW(LSTM_model.parameters(), lr=1e-2, betas=(0.9, 0.95), weight_decay=1e-1)\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    # TRAINING MODE\n",
    "    LSTM_model.train()\n",
    "\n",
    "    # training batch variables\n",
    "    train_batch_loss = 0\n",
    "\n",
    "    for idx, (x, y) in enumerate(train_loader):\n",
    "        # getting encoder input data\n",
    "        feature = x.float().to(device)\n",
    "        target = y.float().to(device)\n",
    "\n",
    "        # forward pass\n",
    "        optimizer.zero_grad()\n",
    "        # predictions = tf_model.forward(enc_input, dec_input, dec_source_mask, dec_target_mask)\n",
    "        predictions = LSTM_model.forward(feature)\n",
    "\n",
    "        loss = criterion(predictions.view(feature.size(0), -1),\n",
    "                         target.contiguous().view(feature.size(0), -1))\n",
    "        train_batch_loss += loss.item()\n",
    "\n",
    "        # updating weights\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    training_loss.append(train_batch_loss/len(train_loader))\n",
    "    print(\"Epoch {}/{}....Training loss = {:.4f}\".format(epoch +\n",
    "                                                         1, epochs, training_loss[-1]))\n",
    "\n",
    "    if (epoch)%10 == 0:\n",
    "        # Saving model, loss and error log files\n",
    "        torch.save({\n",
    "            'model_state_dict': LSTM_model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'training_loss': training_loss,\n",
    "        }, os.path.join(save_location, 'Channel_model_LSTM_epoch{}.pth'.format(epoch+1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "loaded_file = torch.load(os.path.join(\n",
    "    save_location, 'Channel_model_LSTM_epoch91.pth'), map_location=torch.device(device))\n",
    "\n",
    "# creating model and loading weights\n",
    "# encoder_ip_size = 2\n",
    "# decoder_ip_size = 3\n",
    "# model_op_size = 3\n",
    "# emb_size = 512\n",
    "# num_heads = 8\n",
    "# ff_hidden_size = 2048\n",
    "# n = 6\n",
    "# dropout = 0.1\n",
    "\n",
    "# model_loaded = model.TFModel(encoder_ip_size, decoder_ip_size, model_op_size, emb_size,\n",
    "#                              num_heads, ff_hidden_size, n, dropout=0.1)\n",
    "\n",
    "model_loaded = model_LSTM.LSTM(input_size=2, input_seq_len=475,\n",
    "                             hidden_size=128, num_layers=3, output_size=2, output_seq_len=15).to(device)\n",
    "\n",
    "\n",
    "model_loaded = model_loaded.to(device)\n",
    "model_loaded.load_state_dict(loaded_file['model_state_dict'])\n",
    "\n",
    "# loading training metric variables\n",
    "training_loss = loaded_file['training_loss']\n",
    "\n",
    "# plotting training loss\n",
    "plt.figure()\n",
    "plt.plot(training_loss)\n",
    "plt.xlabel(\"Number of epochs\")\n",
    "plt.ylabel(\"Training loss\")\n",
    "plt.title(\"Training loss VS Number of Epochs\")\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluation on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
